import os
import json
import codecs
import csv
from datetime import datetime
from nltk.sentiment import SentimentIntensityAnalyzer
from nltk import download

# === è¨­å®šè·¯å¾‘åƒæ•¸ ===
import sys
from pathlib import Path
parent_dir = Path(__file__).resolve().parent.parent
sys.path.append(str(parent_dir))
from config import COIN_SHORT_NAME, JSON_DICT_NAME

# === ä¸‹è¼‰ VADER æƒ…ç·’å­—å…¸ ===
download('vader_lexicon')
sia = SentimentIntensityAnalyzer()

# === è¨­å®šå¹´ä»½èˆ‡æœˆä»½ ===
YEAR = "2025"
MONTH = "02"

# === è·¯å¾‘è¨­å®š ===
INPUT_DIR = f"../data/filtered_tweets/normal_tweets/{YEAR}/{MONTH}"
POS_DIR = f"../data/sentiment/{COIN_SHORT_NAME}/{YEAR}/{MONTH}/positive"
NEU_DIR = f"../data/sentiment/{COIN_SHORT_NAME}/{YEAR}/{MONTH}/neutral"
NEG_DIR = f"../data/sentiment/{COIN_SHORT_NAME}/{YEAR}/{MONTH}/negative"
CSV_OUTPUT_DIR = f"../data/sentiment/{COIN_SHORT_NAME}/summary"

# å»ºç«‹æ‰€æœ‰è¼¸å‡ºè³‡æ–™å¤¾
os.makedirs(POS_DIR, exist_ok=True)
os.makedirs(NEU_DIR, exist_ok=True)
os.makedirs(NEG_DIR, exist_ok=True)
os.makedirs(CSV_OUTPUT_DIR, exist_ok=True)

# çµ±è¨ˆè³‡æ–™å„²å­˜
summary_data = []

# === é–‹å§‹è™•ç†æ‰€æœ‰ JSON æª”æ¡ˆ ===
for file in sorted(os.listdir(INPUT_DIR)):
    if not file.endswith(".json"):
        continue

    date_str = file.replace(f"{COIN_SHORT_NAME}_", "").replace("_normal.json", "")
    try:
        datetime.strptime(date_str, "%Y%m%d")
    except ValueError:
        print(f"âŒ è·³éŽä¸åˆæ³•æ—¥æœŸæª”æ¡ˆï¼š{file}")
        continue

    filepath = os.path.join(INPUT_DIR, file)
    try:
        with codecs.open(filepath, "r", encoding="utf-8-sig") as f:
            raw = json.load(f)

        if isinstance(raw, dict) and JSON_DICT_NAME in raw:
            tweets = raw[JSON_DICT_NAME]
        else:
            print(f"âŒ æ ¼å¼éŒ¯èª¤æˆ–ç¼ºå°‘ {JSON_DICT_NAME}ï¼š{file}")
            continue
    except Exception as e:
        print(f"âŒ ç„¡æ³•è§£æž {file}ï¼š{e}")
        continue

    # === æƒ…ç·’åˆ†é¡ž ===
    pos, neu, neg = [], [], []
    for tweet in tweets:
        text = tweet.get("text", "")
        if not text.strip():
            continue
        score = sia.polarity_scores(text)
        c = score["compound"]
        if c >= 0.05:
            pos.append(tweet)
        elif c <= -0.05:
            neg.append(tweet)
        else:
            neu.append(tweet)

    # === å„²å­˜åˆ†é¡ž JSON ===
    def save_json(subfolder, name, content):
        path = os.path.join(subfolder, f"{name}.json")
        with open(path, "w", encoding="utf-8") as f:
            json.dump(content, f, ensure_ascii=False, indent=2)

    save_json(POS_DIR, f"{COIN_SHORT_NAME}_{date_str}_positive", pos)
    save_json(NEU_DIR, f"{COIN_SHORT_NAME}_{date_str}_neutral", neu)
    save_json(NEG_DIR, f"{COIN_SHORT_NAME}_{date_str}_negative", neg)

    print(f"âœ… {file} â†’ å®Œæˆåˆ†é¡žï¼šðŸ‘ {len(pos)} | ðŸ˜ {len(neu)} | ðŸ‘Ž {len(neg)}")

    # çµ±è¨ˆè¨˜éŒ„
    summary_data.append({
        "date": date_str,
        "total_tweets": len(pos) + len(neu) + len(neg),
        "positive": len(pos),
        "neutral": len(neu),
        "negative": len(neg)
    })

# === è¼¸å‡º CSV çµ±è¨ˆè¡¨ ===
csv_filename = f"{COIN_SHORT_NAME}_{YEAR}_{MONTH}_sentiment_summary.csv"
csv_path = os.path.join(CSV_OUTPUT_DIR, csv_filename)

with open(csv_path, "w", newline="", encoding="utf-8") as csvfile:
    fieldnames = ["date", "total_tweets", "positive", "neutral", "negative"]
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
    writer.writeheader()
    for row in summary_data:
        writer.writerow(row)

print(f"\nðŸ“Š çµ±è¨ˆç¸½è¡¨å·²å„²å­˜ï¼š{csv_path}")