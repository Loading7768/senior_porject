import numpy as np
import pickle
import pandas as pd

'''å¯ä¿®æ”¹åƒæ•¸'''
COIN_SHORT_NAME = ["DOGE", "PEPE", "TRUMP"]

MODEL_NAME = "logreg"

INPUT_PATH = "../data/ml/dataset"

INPUT_FIRST_CLASSIFIER_PATH = "../data/ml/classification/logistic_regression"

OUTPUT_PATH = "../data/ml/dataset"

MERGE_CLASSIFIER_1_RESULT = True
'''å¯ä¿®æ”¹åƒæ•¸'''

def merge():
    X = []
    Y = []
    all_coin_dates = set()  # ç”¨é›†åˆè‡ªå‹•å»é‡
    ids_all_coin = []

    # å°‡ä¸åŒå¹£ç¨®çš„ X, Y åˆ†åˆ¥è®€å–é€²ä¾†
    for coin_short_name in COIN_SHORT_NAME:
        print(f"\nğŸš© æ­£åœ¨è™•ç† {coin_short_name} ...")

        # --- è®€å– X ---
        X_diff_past = np.load(f"{INPUT_PATH}/coin_price/{coin_short_name}_price_diff_past5days.npy")  # è®€å– å‰é¢å¹¾å¤© çš„ åƒ¹å·®ã€åƒ¹éŒ¢è®ŠåŒ–ç‡
        X_XGBoost = np.load(f"{INPUT_PATH}/coin_price/{coin_short_name}_XGBoost_features.npy")  # è®€å– XBGoost æ‰€ä½¿ç”¨çš„ features
        X_first_classifier = np.load(f"{INPUT_FIRST_CLASSIFIER_PATH}/{coin_short_name}_{MODEL_NAME}_classifier_1_result.npy")  # è®€å– ç¬¬ä¸€å€‹åˆ†é¡å™¨ é æ¸¬çš„çµæœ
        
        # --- è®€å– X çš„æ—¥æœŸåƒè€ƒè³‡æ–™ ---
        XGBoost_dates = np.loadtxt(f"{INPUT_PATH}/coin_price/{coin_short_name}_XGBoost_dates.txt", dtype=str)  # è®€å– XBGoost æ‰€ä½¿ç”¨çš„ dates
        with open(f"{INPUT_PATH}/keyword/{coin_short_name}_ids.pkl", "rb") as f:   # è®€å–ä¸€é–‹å§‹è¨“ç·´ç”¨çš„ ids
            ids = pickle.load(f)
        
        all_coin_dates.update([(c, d) for (c, d, _) in ids])  # åªå– (coin, date) åŠ å…¥é›†åˆ

        # å…ˆæŠŠ all_coin_dates åªä¿ç•™ç•¶å‰å¹£ç¨®çš„æ—¥æœŸ
        current_coin_dates = set([d for (c, d) in all_coin_dates if c == coin_short_name])

        # print("X_XGBoost.shape", X_XGBoost.shape)
        # print("XGBoost_dates[-10:]", XGBoost_dates[-10:])
        # print("current_coin_datesï¼š", sorted(current_coin_dates))
        # print("len(current_coin_dates)ï¼š", len(current_coin_dates))

        # å»ºç«‹ maskï¼Œåªä¿ç•™åœ¨ all_coin_dates è£¡çš„æ—¥æœŸ
        mask = [d in current_coin_dates for d in XGBoost_dates]

        # ç”¨ mask éæ¿¾ X_XGBoost èˆ‡ XGBoost_dates
        X_XGBoost = X_XGBoost[mask]
        XGBoost_dates = XGBoost_dates[mask]  # ç‚ºäº†çœ‹ X_XGBoost æœ‰æ²’æœ‰åˆªæ­£ç¢º

        current_coin_ids = set([(c, d) for (c, d) in all_coin_dates if c == coin_short_name])
        # ids_all_coin += sorted(current_coin_ids)
        print(f"å»æ‰é‡è¤‡æ—¥æœŸå¾Œ {coin_short_name} çš„ (coin, date) æ•¸é‡: {len(current_coin_ids)}\n")
        print(f"{coin_short_name} çš„ XGBoost ç›¸é—œç‰¹å¾µæ—¥æœŸçš„å¾Œ 10 å¤©ï¼š(ç”¨ä¾†æª¢æŸ¥ X_XGBoost æœ‰æ²’æœ‰å–æ­£ç¢º DOGEã€TRUMPå‰é¢æœƒå°‘ 13 å¤©)\n{XGBoost_dates[-10:]}\n")

        # print("X_diff_past.shape:", X_diff_past.shape)
        # print("X_XGBoost.shape:", X_XGBoost.shape)
        # print("X_first_classifier.shape:", X_first_classifier.shape)

        # --- è®€å– Y ---
        Y_single_coin = np.load(f"{INPUT_PATH}/coin_price/{coin_short_name}_price_diff_original.npy")  # è®€å– æ˜å¤© çš„åƒ¹éŒ¢è®ŠåŒ–ç‡ (price_diff_rate_tomorrow)
        print("Y_single_coin.shape:", Y_single_coin.shape)

        # # --- å°é½Šæ™‚é–“è»¸ ---
        # if coin_short_name == "PEPE":  # å› ç‚º PEPE ä¸æ˜¯å¾ç™¼å”®å°±é–‹å§‹æŠ“æ¨æ–‡ æ‰€ä»¥ X_XGBoost æ²’æœ‰è¢«è·³é 13 å¤©
        #     start_idx = 5   # å› ç‚º X_diff_past ç‰¹å¾µè¦è·³éå‰ 5 å¤©
        #     X_XGBoost = X_XGBoost[start_idx:]
        #     X_first_classifier = X_first_classifier[start_idx:]
        #     Y_single_coin = Y_single_coin[start_idx:]
        # elif coin_short_name == "TRUMP":  # å› ç‚º TRUMP åœ¨ 2025-01-27 æ²’æœ‰æŠ“åˆ°è³‡æ–™ ä½†æ­¤æ—¥æœŸåŒ…å«åœ¨ X_XGBoost æ‰€è·³éçš„ 13 å¤©å…§
        #     start_idx = 12   # å› ç‚º XGBoost ç‰¹å¾µè¦è·³éå‰ 13 å¤© ä½†è¦ -1
        #     X_diff_past = X_diff_past[(start_idx - 5):]  # åŸæœ¬å°‘ 5 å¤© â†’ å†åˆ‡æ‰åˆ° 7
        #     X_first_classifier = X_first_classifier[start_idx:]
        #     Y_single_coin = Y_single_coin[start_idx:]
        # elif coin_short_name == "DOGE":
        #     start_idx = 13   # å› ç‚º XGBoost ç‰¹å¾µè¦è·³éå‰ 13 å¤©
        #     X_diff_past = X_diff_past[(start_idx - 5):]  # åŸæœ¬å°‘ 5 å¤© â†’ å†åˆ‡æ‰åˆ° 8
        #     X_first_classifier = X_first_classifier[start_idx:]
        #     Y_single_coin = Y_single_coin[start_idx:]

        # --- å°é½Šæ™‚é–“è»¸ï¼ˆå¾å¾Œé¢å°é½Šï¼‰ ---
        min_len = min(len(X_diff_past), len(X_XGBoost), len(X_first_classifier), len(Y_single_coin))
        X_diff_past = X_diff_past[-min_len:]
        X_XGBoost = X_XGBoost[-min_len:]
        X_first_classifier = X_first_classifier[-min_len:]
        Y_single_coin = Y_single_coin[-min_len:]
        ids_all_coin += (sorted(current_coin_ids)[-min_len:])

        print(f"ç›®å‰ ids_all_coin (è¦è¼¸å‡ºçš„ ids) å…§å®¹ï¼š(æ‡‰è©²ä¸‰å€‹å¹£ç¨®éƒ½è¦é•·ä¸€æ¨£)\n{ids_all_coin[:10]}\n")
        print(f"ids_all_coin (è¦è¼¸å‡ºçš„ ids) çš„é•·åº¦ï¼š{len(ids_all_coin)}\n")

        # --- åˆä½µç‰¹å¾µ ---
        if MERGE_CLASSIFIER_1_RESULT:
            X_single_coin = np.hstack([X_diff_past, X_XGBoost, X_first_classifier.reshape(-1, 1)])
        else:
            X_single_coin = np.hstack([X_diff_past, X_XGBoost])
        
    
        # --- å­˜é€²ç¸½é›†åˆ ---
        X.append(X_single_coin)
        Y.append(Y_single_coin)

    # --- æŠŠä¸‰å€‹å¹£ç¨®åˆä½µæˆä¸€å€‹å¤§é™£åˆ— ---
    X = np.vstack(X)
    Y = np.concatenate(Y)

    print("\nâœ… å·²ç¶“å®Œæˆåˆä½µ\n")

    return X, Y, ids_all_coin

def export_to_csv(X, Y, ids, output_path=f"{MODEL_NAME}_merged_dataset.csv"):
    # æŠŠ ids æ‹†æˆ coin / date
    coins = [c for c, d in ids]
    dates = [d for c, d in ids]

    # å»ºç«‹ DataFrame
    df = pd.DataFrame({
        "coin": coins,
        "date": dates,
        "label": Y
    })

    # å¦‚æœ X æœ‰ featureï¼Œå‰‡å±•é–‹
    if X.ndim == 2:
        feature_df = pd.DataFrame(X, columns=[f"f{i}" for i in range(X.shape[1])])
        df = pd.concat([df, feature_df], axis=1)
    else:
        # ä¸€ç¶­æˆ–å…¶ä»–æƒ…æ³ç›´æ¥å­˜
        df["feature"] = X

    # å­˜æˆ CSV
    df.to_csv(output_path, index=False, encoding="utf-8")
    print(f"âœ… è¼¸å‡ºå®Œæˆ: {output_path}")



def main():
    X, Y, ids = merge()

    print("len(ids) =", len(ids))
    print("X.shape =", X.shape)
    print("Y.shape =", Y.shape)

    # ç”¨æ³•
    export_to_csv(X, Y, ids, f"{OUTPUT_PATH}/{MODEL_NAME}_merged_dataset.csv")

    print("ğŸš© æ‰“äº‚å‰ï¼š")
    print("\nX é è¦½ï¼š\n", X[:10])
    print("\nY é è¦½ï¼š\n", Y[:10])
    print("\nids é è¦½ï¼š\n", ids[:10])

    # --- æ‰“äº‚ X, Y, ids ---
    rng = np.random.default_rng(42)  # å¯è‡ªè¨‚ç¨®å­
    indices = np.arange(Y.shape[0])
    rng.shuffle(indices)

    # print("Before shuffle:", Y[0], ids[0])
    # print("Index mapping:", indices[:10])  # çœ‹å‰10ç­†æ‰“äº‚é †åº
    # print("After shuffle:", Y[indices[0]], ids[indices[0]])

    # k = 619  # èˆŠçš„ index
    # print("Original:", Y[k], ids[k])
    # print("Shuffled:", Y[indices.tolist().index(k)], ids[indices.tolist().index(k)])

    X = X[indices]
    Y = Y[indices]
    ids = np.array(ids)[indices]

    print("\nğŸš© æ‰“äº‚å¾Œï¼š")
    print("\nX é è¦½ï¼š\n", X[:10])
    print("\nY é è¦½ï¼š\n", Y[:10])
    print("\nids é è¦½ï¼š\n", ids[:10])

    # å„²å­˜
    np.save(f"{OUTPUT_PATH}/{MODEL_NAME}_X_classifier_2.npy", X)
    np.save(f"{OUTPUT_PATH}/{MODEL_NAME}_Y_classifier_2.npy", Y)
    with open(f"{OUTPUT_PATH}/{MODEL_NAME}_ids_classifier_2.pkl", 'wb') as file:
        pickle.dump(ids, file)  # é€™è£¡åªæœƒå­˜ ('coin', 'date') ä¸”æ¯å€‹æ—¥æœŸåªæœ‰ä¸€ç­†

    print(f"\nâœ… å·²æˆåŠŸå„²å­˜è‡³ {OUTPUT_PATH}\n")

if __name__ == "__main__":
    main()
