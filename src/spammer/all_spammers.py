import os
from datetime import datetime
from collections import defaultdict
from tqdm import tqdm
import csv
import json

from pathlib import Path
import sys
parent_dir = Path(__file__).resolve().parent.parent
sys.path.append(str(parent_dir))
from config import JSON_DICT_NAME, COIN_SHORT_NAME

# === è‡ªè¨‚åƒæ•¸ ===
LIMIT_DAY = 50      # æ¯å¤©ç¸½æŽ¨æ–‡æ•¸è¶…éŽé€™å€‹å°±æ˜¯é«˜ç™¼æ–‡å¤©
LIMIT_HOUR = 6      # å°æ™‚å…§æŽ¨æ–‡è¶…éŽé€™å€‹å°±æ˜¯é«˜å°æ™‚ç™¼æ–‡
TOTAL_COUNT = 5     # ç›¸åŠ æ•¸å­— >= 5 çš„è©±å°±ç®— spammer
root_folder = f"../data/author_all/{COIN_SHORT_NAME}"
output_folder = f"../data/spammer/{COIN_SHORT_NAME}/"
os.makedirs(output_folder, exist_ok=True)
csv_file = os.path.join(output_folder, f"{COIN_SHORT_NAME}_high_post_summary.csv")
spammer_list_file = os.path.join(output_folder, f"{COIN_SHORT_NAME}_spammers.txt")

# è§£æžæ™‚é–“
# def parse_time(s):
#     try:
#         return datetime.strptime(s, "%a %b %d %H:%M:%S %z %Y")
#     except:
#         return None

# author -> date -> count
author_day_counts = defaultdict(lambda: defaultdict(int))
author_hour_counts = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))

# æ”¶é›†æ‰€æœ‰ JSON æª”
all_files = []
for dirpath, _, filenames in os.walk(root_folder):
    for filename in sorted(filenames):
        if filename.endswith(".json"):
            all_files.append(os.path.join(dirpath, filename))

print(f"ðŸ” æº–å‚™è™•ç† {len(all_files)} å€‹æª”æ¡ˆ...")

# æµå¼è§£æž JSON
for file_path in tqdm(all_files, desc="è®€å– JSON æª”æ¡ˆ"):
    try:
        with open(file_path, "r", encoding="utf-8-sig") as f:
            data = json.load(f)

        tweets = data.get(JSON_DICT_NAME, [])
        if not isinstance(tweets, list):
            continue

        for tw in tweets:
            user = tw.get("user_account") or tw.get("username")
            t = datetime.strptime(tw.get("created_at", ""), "%a %b %d %H:%M:%S %z %Y")
            if user and t:
                date = t.date()
                hour = t.hour
                author_day_counts[user][date] += 1
                author_hour_counts[user][date][hour] += 1
    except Exception as e:
        print(f"âŒ è®€å–å¤±æ•—ï¼š{file_path}ï¼ŒéŒ¯èª¤ï¼š{e}")
        continue

# è¨ˆç®—å¤©æ•¸
summary = {}
spammers = set()
for user in set(list(author_day_counts.keys()) + list(author_hour_counts.keys())):
    # æ¯å¤©ç¸½æŽ¨æ–‡ >= LIMIT_DAY
    high_day_count = sum(1 for count in author_day_counts[user].values() if count >= LIMIT_DAY)
    # æ¯å¤©ä»»ä¸€å°æ™‚ >= LIMIT_HOUR
    high_hour_count = sum(1 for hour_dict in author_hour_counts[user].values() if any(c >= LIMIT_HOUR for c in hour_dict.values()))
    summary[user] = (high_day_count, high_hour_count)

    # åˆ¤æ–· spammerï¼šå…©å€‹çµ±è¨ˆç›¸åŠ  >= TOTAL_COUNT
    if high_day_count + high_hour_count >= TOTAL_COUNT:
        spammers.add(user)

# è¼¸å‡º CSVï¼Œåªåˆ—å‡ºä»»ä¸€çµ±è¨ˆå¤§æ–¼ 0 çš„å¸³è™Ÿ
with open(csv_file, "w", encoding="utf-8-sig", newline="") as f:
    writer = csv.writer(f)
    writer.writerow([
        "user_account",
        f"days_over_{LIMIT_DAY}_tweets",
        f"days_hour_ge_{LIMIT_HOUR}_tweets",
        "total_days_over_limit"
    ])
    for user, (day_count, hour_count) in sorted(summary.items()):
        if day_count > 0 or hour_count > 0:  # åªåˆ—å‡ºä»»ä¸€å¤§æ–¼ 0
            total = day_count + hour_count
            writer.writerow([user, day_count, hour_count, total])

print(f"âœ… é«˜ç™¼æ–‡å¤©æ•¸èˆ‡é«˜å°æ™‚ç™¼æ–‡å¤©æ•¸ CSV å·²å­˜å…¥ï¼ˆåªåˆ—å‡ºä»»ä¸€å¤§æ–¼ 0ï¼‰: {csv_file}")

# è¼¸å‡º spammer åå–®åˆ°æ–‡å­—æª”
with open(spammer_list_file, "w", encoding="utf-8-sig") as f:
    for user in sorted(spammers):
        f.write(user + "\n")

print(f"âœ… Spammer åå–®å·²å­˜å…¥ï¼š{spammer_list_file} ï¼ˆdays_over + hours_over >= 5ï¼‰")

