from collections import defaultdict
import os
import json
import pandas as pd
from datetime import datetime, timedelta
from glob import glob
from tqdm import tqdm
import numpy as np

import sys
from pathlib import Path
parent_dir = Path(__file__).resolve().parent.parent
sys.path.append(str(parent_dir))
from config import COIN_SHORT_NAME, JSON_DICT_NAME

'''
è¦å…ˆæŠŠåƒ¹éŒ¢å’Œæ—¥æœŸçš„ csv æª”æ”¾åœ¨ ../data/coin_price ä¸­
æª”åå­˜ç‚º {COIN_SHORT_NAME}_price.csv

DOGE_price.csvï¼š
    snapped_at,price,market_cap,total_volume
    2014-01-28 00:00:00 UTC,0.00134193,50833265.0,2342040.0
    2014-01-29 00:00:00 UTC,0.00138856,53584322.0,1655470.0
    2014-01-30 00:00:00 UTC,0.00147485,58009736.0,2315200.0
    ...
'''


'''å¯ä¿®æ”¹åƒæ•¸'''
# === ä¿®æ”¹ç‚ºä½ çš„ CSV æª”èˆ‡ JSON è³‡æ–™å¤¾è·¯å¾‘ ===
PRICE_CSV_PATH = f"../data/coin_price/{COIN_SHORT_NAME}_price.csv"
NORMAL_TWEETS_JSON_GLOB = f"../data/filtered_tweets/normal_tweets/*/*/*.json"  # æ˜¯é‡å° normal_tweet åšé‹ç®—
OUTPUT_CSV_PATH = f"../data/coin_price/{COIN_SHORT_NAME}_current_tweet_price_output.csv"

# === è‡ªè¨‚æ™‚é–“ç¯„åœ (æ ¼å¼ï¼šYYYY/MM/DD) ===
START_DATE = "2013/12/15"
END_DATE   = "2025/07/31"
'''å¯ä¿®æ”¹åƒæ•¸'''



# è½‰æˆ datetime æ–¹ä¾¿æ¯”è¼ƒ
START_DATE_DT = pd.to_datetime(START_DATE, format="%Y/%m/%d")
END_DATE_DT   = pd.to_datetime(END_DATE, format="%Y/%m/%d")

# === è®€å–åƒ¹æ ¼ CSV ===
price_df = pd.read_csv(PRICE_CSV_PATH)
price_df['snapped_at'] = pd.to_datetime(price_df['snapped_at'], format="%Y-%m-%d %H:%M:%S %Z")
price_df.set_index('snapped_at', inplace=True)
price_df.index = price_df.index.tz_localize(None)  # ç§»é™¤æ™‚å€ åªä¿ç•™æ—¥æœŸéƒ¨åˆ†

# ðŸ”¹ éŽæ¿¾åƒ¹æ ¼è³‡æ–™åˆ°æ™‚é–“ç¯„åœå…§
price_df = price_df.loc[(price_df.index >= START_DATE_DT) & (price_df.index <= END_DATE_DT + pd.Timedelta(days=1))]


# === å„²å­˜æŽ¨æ–‡è³‡è¨Š è‹¥ç•¶å¤©æ²’æœ‰æŽ¨æ–‡å‰‡ä¸æœƒåŠ é€²åŽ» set ä¸­ ===
tweet_dates = set()  # æ”¶é›† tweet æœ‰å‡ºç¾çš„æ—¥æœŸ

tweet_count = defaultdict(int)  # å„²å­˜æ¯å¤©çš„æŽ¨æ–‡æ•¸é‡


json_files = glob(NORMAL_TWEETS_JSON_GLOB)
for json_path in tqdm(json_files, desc="æ­£åœ¨æ‰¾å°‹æ—¥æœŸ"):
    with open(json_path, "r", encoding="utf-8-sig") as f:
        data = json.load(f)

    tweets = data[JSON_DICT_NAME]
    if not tweets:
        continue

    try:
        # å–å¾—æ—¥æœŸ
        date_str = datetime.strptime(
            tweets[0]['created_at'], "%a %b %d %H:%M:%S %z %Y"
        ).strftime("%Y/%m/%d")
        date_dt = pd.to_datetime(date_str)
        tweet_dates.add(date_dt)

        # ðŸ”¹ éŽæ¿¾æŽ‰ä¸åœ¨ç¯„åœå…§çš„æŽ¨æ–‡
        if not (START_DATE_DT <= date_dt <= END_DATE_DT):
            continue

        # å–å¾—ç•¶å¤©æŽ¨æ–‡æ•¸é‡
        tweet_count[date_dt] = len(tweets)

    except Exception as e:
        print(f"[éŒ¯èª¤] {json_path}: {e}")

# === ä¾ç…§ tweet æ—¥æœŸæŽ’åºï¼Œæ±ºå®šæ•´å€‹æ™‚é–“ç¯„åœ ===
if not tweet_dates:
    print("æ²’æœ‰æŠ“åˆ°ä»»ä½•æŽ¨æ–‡æ—¥æœŸ")
    exit()

tweet_dates = sorted(tweet_dates)  # å› ç‚ºæŠ“é€²ä¾†çš„æª”æ¡ˆé †åºå¯èƒ½æœƒæ˜¯äº‚çš„

# ----------- å°‡ tweet_count è¼¸å‡ºæˆ json æª” -------------
# å°‡ datetime è½‰æˆå­—ä¸²ï¼Œdefaultdict -> dict
tweet_count_dict = {
    date.strftime("%Y/%m/%d"): count
    for date, count in sorted(tweet_count.items())  # <- é€™è£¡ sorted æœƒä¾ datetime å‡åºæŽ’åº
}

# å„²å­˜æˆ JSON
output_tweet_count_path = "../data/ml/dataset/coin_price"
os.makedirs(output_tweet_count_path, exist_ok=True)
output_tweet_count_path_file = f"{output_tweet_count_path}/{COIN_SHORT_NAME}_current_tweet_count.json"
with open(output_tweet_count_path_file, "w", encoding="utf-8") as f:
    json.dump(tweet_count_dict, f, ensure_ascii=False, indent=4)

print(f"âœ… å·²å„²å­˜ {COIN_SHORT_NAME}_tweet_count åˆ° {output_tweet_count_path_file}")

total_tweets = sum(tweet_count.values())
print(f"\nå…¨éƒ¨ normal_tweet çš„æŽ¨æ–‡æ•¸é‡: {total_tweets}\n")

# === å»ºç«‹æœ€çµ‚çµæžœè¡¨ ===
output_rows = []

prev_date = None
for current_date in tqdm(tweet_dates, desc="æ­£åœ¨å„²å­˜åƒ¹éŒ¢"):
    if prev_date:

        # è‹¥æœ‰ç¼ºå°‘çš„æ—¥æœŸ ä¸” ç›¸é„°å…©å¤©é–“å°‘æ–¼ 31 å¤©
        gap = (current_date - prev_date).days
        if 1 < gap < 31:
            for d in pd.date_range(prev_date + timedelta(days=1), current_date - timedelta(days=1)):
                
                row = price_df.loc[price_df.index == d]
                price = row['price'].values[0] if not row.empty else ""

                output_rows.append({
                    "date": d.strftime("%Y/%m/%d"),
                    "price": price,
                    "tweet_count": 0,
                    "has_tweet": False
                })
    # ç•¶å‰ tweet æ—¥æœŸ
    price = price_df.loc[current_date]['price'] if current_date in price_df.index else ""
    output_rows.append({
        "date": current_date.strftime("%Y/%m/%d"),
        "price": price,
        "tweet_count": tweet_count[current_date],
        "has_tweet": True
    })
    prev_date = current_date

# å°‡ output_rows è½‰æˆ DataFrame
df_output = pd.DataFrame(output_rows)

# å°‡ date å­—ä¸²è½‰æˆ datetimeï¼ˆæ–¹ä¾¿è¨ˆç®—éš”å¤©æ—¥æœŸï¼‰
df_output['date_dt'] = pd.to_datetime(df_output['date'], format='%Y/%m/%d')

# å®šç¾©ä¸€å€‹å‡½æ•¸è¨ˆç®— price å·®
def calc_price_diff(row):
    today = row['date_dt']
    tomorrow = today + pd.Timedelta(days=1)
    try:
        price_today = row['price']
        price_tomorrow = price_df.loc[tomorrow]['price']
        if price_today == "" or pd.isna(price_today):
            return ""
        return price_tomorrow - price_today
    except KeyError:
        return ""  # éš”å¤©æ²’åƒ¹æ ¼å°±ç©ºå­—ä¸²

# è¨ˆç®—å·®åƒ¹æ¬„ä½
df_output['price_diff'] = df_output.apply(calc_price_diff, axis=1)

# åˆªé™¤è¼”åŠ©æ¬„ä½
df_output.drop(columns=['date_dt'], inplace=True)

# å„²å­˜åŽŸæœ¬çš„ CSV
df_output.to_csv(OUTPUT_CSV_PATH, index=False, encoding="utf-8-sig")
print(f"âœ… å·²å„²å­˜åˆ° {OUTPUT_CSV_PATH}")

# å°‡ price_diff æ¬„ä½è½‰ç‚º floatï¼ŒNaN å°±æœƒé¡¯ç¾å‡ºä¾†
df_output['price_diff_float'] = pd.to_numeric(df_output['price_diff'], errors='coerce')

# æ‰¾å‡º NaN çš„åˆ—
nan_rows = df_output[df_output['price_diff_float'].isna()]

# é¡¯ç¤ºæ˜¯å“ªå¹¾å¤©
print("\nä»¥ä¸‹æ—¥æœŸ price_diff ç„¡æ³•è¨ˆç®—ï¼ˆå¯èƒ½ç¼ºå°‘ç•¶å¤©æˆ–éš”å¤©åƒ¹æ ¼ï¼‰:")
print(nan_rows[['date', 'price', 'tweet_count', 'has_tweet']])


# ----------------------- å„²å­˜ price_diff.npy --------------------------
# å…ˆæŠŠç©ºå­—ä¸²è½‰æˆ NaNï¼Œæ–¹ä¾¿è™•ç†ï¼ˆé€™ä¸€æ­¥æœƒå°‡éžæ•¸å€¼éƒ½è½‰æˆ NaNï¼‰
df_output['price_diff'] = pd.to_numeric(df_output['price_diff'], errors='coerce')

# éŽæ¿¾å‡º has_tweet == True çš„è³‡æ–™ï¼Œä¸” price_diff ä¸æ˜¯ NaN
filtered_df = df_output[(df_output['has_tweet'] == True) & (df_output['price_diff'].notna())]

# ä¾ tweet_count é‡è¤‡ price_diff
expanded_price_diffs = []
for _, row in filtered_df.iterrows():  # é€è¡Œéæ­· filtered_df
    expanded_price_diffs.extend([row['price_diff']] * row['tweet_count'])  # extend() æ–¹æ³•æœƒæŠŠé€™å€‹ list çš„æ‰€æœ‰å…ƒç´ åŠ åˆ° expanded_price_diffs è£¡

price_diff_array = np.array(expanded_price_diffs, dtype=float)  # è½‰æˆ numpy é™£åˆ—
np.save(f"../data/ml/dataset/coin_price/{COIN_SHORT_NAME}_price_diff.npy", price_diff_array)  # å­˜æˆ .npy æª”

# é¡¯ç¤ºé è¦½
print(f"\nâœ… å·²å„²å­˜ {COIN_SHORT_NAME}_price_diff.npyï¼ˆå…± {len(price_diff_array)} ç­†ï¼‰ï¼š\n{price_diff_array}")

