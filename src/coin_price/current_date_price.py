from collections import defaultdict
import os
import json
import pandas as pd
from datetime import datetime, timedelta
from glob import glob
from tqdm import tqdm
import numpy as np

import sys
from pathlib import Path
parent_dir = Path(__file__).resolve().parent.parent
sys.path.append(str(parent_dir))
from config import COIN_SHORT_NAME, JSON_DICT_NAME

'''
è¦å…ˆæŠŠåƒ¹éŒ¢å’Œæ—¥æœŸçš„ csv æª”æ”¾åœ¨ ../data/coin_price ä¸­
æª”åå­˜ç‚º {COIN_SHORT_NAME}_price.csv

DOGE_price.csvï¼š
    snapped_at,price,market_cap,total_volume
    2014-01-28 00:00:00 UTC,0.00134193,50833265.0,2342040.0
    2014-01-29 00:00:00 UTC,0.00138856,53584322.0,1655470.0
    2014-01-30 00:00:00 UTC,0.00147485,58009736.0,2315200.0
    ...
'''


'''å¯ä¿®æ”¹åƒæ•¸'''
# === ä¿®æ”¹ç‚ºä½ çš„ CSV æª”èˆ‡ JSON è³‡æ–™å¤¾è·¯å¾‘ ===
PRICE_CSV_PATH = f"../data/coin_price/{COIN_SHORT_NAME}_price.csv"
NORMAL_TWEETS_JSON_GLOB = f"../data/filtered_tweets/normal_tweets/*/*/*.json"  # æ˜¯é‡å° normal_tweet åšé‹ç®—
OUTPUT_CSV_PATH = f"../data/coin_price/{COIN_SHORT_NAME}_current_tweet_price_output.csv"

# === è‡ªè¨‚æ™‚é–“ç¯„åœ (æ ¼å¼ï¼šYYYY/MM/DD) ===
START_DATE = "2013/12/15"
END_DATE   = "2025/07/31"

SHIFT = 5
'''å¯ä¿®æ”¹åƒæ•¸'''



# è½‰æˆ datetime æ–¹ä¾¿æ¯”è¼ƒ
START_DATE_DT = pd.to_datetime(START_DATE, format="%Y/%m/%d")
END_DATE_DT   = pd.to_datetime(END_DATE, format="%Y/%m/%d")

# === è®€å–åƒ¹æ ¼ CSV ===
price_df = pd.read_csv(PRICE_CSV_PATH)
price_df['snapped_at'] = pd.to_datetime(price_df['snapped_at'], format="%Y-%m-%d %H:%M:%S %Z")
price_df.set_index('snapped_at', inplace=True)
price_df.index = price_df.index.tz_localize(None)  # ç§»é™¤æ™‚å€ åªä¿ç•™æ—¥æœŸéƒ¨åˆ†

# ðŸ”¹ éŽæ¿¾åƒ¹æ ¼è³‡æ–™åˆ°æ™‚é–“ç¯„åœå…§
price_df = price_df.loc[(price_df.index >= START_DATE_DT) & (price_df.index <= END_DATE_DT + pd.Timedelta(days=1))]


# === å„²å­˜æŽ¨æ–‡è³‡è¨Š è‹¥ç•¶å¤©æ²’æœ‰æŽ¨æ–‡å‰‡ä¸æœƒåŠ é€²åŽ» set ä¸­ ===
tweet_dates = set()  # æ”¶é›† tweet æœ‰å‡ºç¾çš„æ—¥æœŸ

tweet_count = defaultdict(int)  # å„²å­˜æ¯å¤©çš„æŽ¨æ–‡æ•¸é‡


json_files = glob(NORMAL_TWEETS_JSON_GLOB)
for json_path in tqdm(json_files, desc="æ­£åœ¨æ‰¾å°‹æ—¥æœŸ"):
    with open(json_path, "r", encoding="utf-8-sig") as f:
        data = json.load(f)

    tweets = data[JSON_DICT_NAME]
    if not tweets:
        continue

    try:
        # å–å¾—æ—¥æœŸ
        date_str = datetime.strptime(
            tweets[0]['created_at'], "%a %b %d %H:%M:%S %z %Y"
        ).strftime("%Y/%m/%d")
        date_dt = pd.to_datetime(date_str)
        tweet_dates.add(date_dt)

        # ðŸ”¹ éŽæ¿¾æŽ‰ä¸åœ¨ç¯„åœå…§çš„æŽ¨æ–‡
        if not (START_DATE_DT <= date_dt <= END_DATE_DT):
            continue

        # å–å¾—ç•¶å¤©æŽ¨æ–‡æ•¸é‡
        tweet_count[date_dt] = len(tweets)

    except Exception as e:
        print(f"[éŒ¯èª¤] {json_path}: {e}")

# === ä¾ç…§ tweet æ—¥æœŸæŽ’åºï¼Œæ±ºå®šæ•´å€‹æ™‚é–“ç¯„åœ ===
if not tweet_dates:
    print("æ²’æœ‰æŠ“åˆ°ä»»ä½•æŽ¨æ–‡æ—¥æœŸ")
    exit()

tweet_dates = sorted(tweet_dates)  # å› ç‚ºæŠ“é€²ä¾†çš„æª”æ¡ˆé †åºå¯èƒ½æœƒæ˜¯äº‚çš„

# ----------- å°‡ tweet_count è¼¸å‡ºæˆ json æª” -------------
# å°‡ datetime è½‰æˆå­—ä¸²ï¼Œdefaultdict -> dict
tweet_count_dict = {
    date.strftime("%Y/%m/%d"): count
    for date, count in sorted(tweet_count.items())  # <- é€™è£¡ sorted æœƒä¾ datetime å‡åºæŽ’åº
}

# å„²å­˜æˆ JSON
output_tweet_count_path = "../data/ml/dataset/coin_price"
os.makedirs(output_tweet_count_path, exist_ok=True)
output_tweet_count_path_file = f"{output_tweet_count_path}/{COIN_SHORT_NAME}_current_tweet_count.json"
with open(output_tweet_count_path_file, "w", encoding="utf-8") as f:
    json.dump(tweet_count_dict, f, ensure_ascii=False, indent=4)

print(f"âœ… å·²å„²å­˜ {COIN_SHORT_NAME}_tweet_count åˆ° {output_tweet_count_path_file}")

total_tweets = sum(tweet_count.values())
print(f"\nå…¨éƒ¨ normal_tweet çš„æŽ¨æ–‡æ•¸é‡: {total_tweets}\n")

# === å»ºç«‹æœ€çµ‚çµæžœè¡¨ ===
output_rows = []

prev_date = None
for current_date in tqdm(tweet_dates, desc="æ­£åœ¨å„²å­˜åƒ¹éŒ¢"):
    if prev_date:

        # è‹¥æœ‰ç¼ºå°‘çš„æ—¥æœŸ ä¸” ç›¸é„°å…©å¤©é–“å°‘æ–¼ 31 å¤©
        gap = (current_date - prev_date).days
        if 1 < gap < 31:
            for d in pd.date_range(prev_date + timedelta(days=1), current_date - timedelta(days=1)):
                
                row = price_df.loc[price_df.index == d]
                price = row['price'].values[0] if not row.empty else ""

                output_rows.append({
                    "date": d.strftime("%Y/%m/%d"),
                    "price": price,
                    "tweet_count": 0,
                    "has_tweet": False
                })
    # ç•¶å‰ tweet æ—¥æœŸ
    price = price_df.loc[current_date]['price'] if current_date in price_df.index else ""
    output_rows.append({
        "date": current_date.strftime("%Y/%m/%d"),
        "price": price,
        "tweet_count": tweet_count[current_date],
        "has_tweet": True
    })
    prev_date = current_date


# å°‡ output_rows è½‰æˆ DataFrame
df_output = pd.DataFrame(output_rows)

# è½‰æ›æ—¥æœŸæ ¼å¼ï¼ˆæ–¹ä¾¿å¾ŒçºŒè¨ˆç®—ï¼‰
df_output['date_dt'] = pd.to_datetime(df_output['date'], format='%Y/%m/%d')
df_output['price'] = pd.to_numeric(df_output['price'], errors='coerce')

# # ---------------- è¨ˆç®— 1~5 å¤©çš„åƒ¹å·® ----------------
# day_shifts = [shift for shift in range(1, SHIFT + 1)]

# for shift in day_shifts:
#     col_name = f"price_diff_{shift}d"

#     def calc_price_diff_shift(row, shift=shift):
#         today = row['date_dt']
#         future = today + pd.Timedelta(days=shift)
#         try:
#             price_today = row['price']
#             price_future = price_df.loc[future]['price']
#             if pd.isna(price_today):
#                 return np.nan
#             return price_future - price_today
#         except KeyError:
#             return np.nan  # ç¼ºå°‘æœªä¾†åƒ¹æ ¼

#     df_output[col_name] = df_output.apply(calc_price_diff_shift, axis=1)

# ---------------- è¨ˆç®—ç›¸é„°æ—¥æœŸçš„åƒ¹å·® ----------------
# å°‡ price_df çš„åƒ¹æ ¼å°é½Š df_output çš„æ—¥æœŸ
price_map = price_df['price'].to_dict()

# è¨ˆç®—æ˜Žå¤©åƒ¹æ ¼ï¼šç›´æŽ¥ç”¨ price_map æŸ¥éš”å¤©
df_output['price_tomorrow'] = df_output['date_dt'].apply(
    lambda x: price_map.get(x + pd.Timedelta(days=1), np.nan)
)

# è¨ˆç®—æ˜Žå¤© - ä»Šå¤©
df_output['price_diff_tomorrow'] = df_output['price_tomorrow'] - df_output['price']
df_output['price_diff_rate_tomorrow'] = df_output['price_diff_tomorrow'] / df_output['price']

# å‹•æ…‹ç”Ÿæˆã€Œå¾€å›ž SHIFT å¤©ã€çš„åƒ¹å·®èˆ‡è®ŠåŒ–çŽ‡
for i in range(1, SHIFT + 1):
    col_price_prev = f"price_{i}daysbefore"
    df_output[col_price_prev] = df_output['price'].shift(i)

    col_diff = f"price_diff_{i}daysbefore"
    col_rate = f"price_diff_rate_{i}daysbefore"

    # åƒ¹å·®ï¼š (i-1) å¤©å‰åƒ¹æ ¼ - i å¤©å‰åƒ¹æ ¼
    df_output[col_diff] = df_output['price'].shift(i - 1) - df_output['price'].shift(i)

    # åƒ¹å·®è®ŠåŒ–çŽ‡ï¼šå·® Ã· iå¤©å‰åƒ¹æ ¼
    df_output[col_rate] = df_output[col_diff] / df_output['price'].shift(i)

# ç§»é™¤è¼”åŠ©æ¬„ä½ï¼ˆæ‰€æœ‰ shift å‡ºä¾†çš„ price_*ï¼‰
drop_cols = ['date_dt'] + ['price_tomorrow'] + [f"price_{i}daysbefore" for i in range(1, SHIFT + 1)]
df_output.drop(columns=drop_cols, inplace=True)

# å„²å­˜ CSV
df_output.to_csv(OUTPUT_CSV_PATH, index=False, encoding="utf-8-sig")
print(f"âœ… å·²å„²å­˜åˆ° {OUTPUT_CSV_PATH}")


# ---------------- å„²å­˜ price_diff_rate_tomorrow åˆ° numpy ----------------
# éŽæ¿¾å‡ºæœ‰æŽ¨æ–‡ä¸” price_diff_rate_tomorrow ä¸æ˜¯ NaN
filtered_df = df_output[(df_output['has_tweet'] == True) & (df_output['price_diff_rate_tomorrow'].notna())]

# ä¾ tweet_count é‡è¤‡åƒ¹å·®
expanded_price_diffs = []
for _, row in filtered_df.iterrows():
    expanded_price_diffs.extend([row['price_diff_rate_tomorrow']] * row['tweet_count'])

# è½‰æˆ numpy é™£åˆ—ä¸¦å„²å­˜
price_diff_array = np.array(expanded_price_diffs, dtype=float)
save_path = f"../data/ml/dataset/coin_price/{COIN_SHORT_NAME}_price_diff.npy"
np.save(save_path, price_diff_array)

print(expanded_price_diffs[:20])  # é è¦½å‰ 20 ç­†
print(f"\nâœ… å·²å„²å­˜ price_diff_rate_tomorrow çŸ©é™£åˆ° {save_path}ï¼Œå…±: {len(expanded_price_diffs)} ç­†\n")


# ---------------- å„²å­˜éŽåŽ» SHIFT å¤©çš„åƒ¹å·®åŠè®ŠåŒ–çŽ‡ ----------------
# åªä¿ç•™æ²’æœ‰ NaN çš„è¡Œ
df_output_clean = df_output.dropna()

columns_to_save = []
for i in range(1, SHIFT + 1):
    columns_to_save.append(f'price_diff_{i}daysbefore')
    columns_to_save.append(f'price_diff_rate_{i}daysbefore')

# éŽæ¿¾æŽ‰æœ‰ NaN çš„è¡Œ
filtered_df = df_output.dropna(subset=columns_to_save)

# éŽæ¿¾æœ‰æŽ¨æ–‡ä¸”å°æ‡‰æ¬„ä½ä¸æ˜¯ NaN
filtered_df = filtered_df[filtered_df['has_tweet'] == True].copy()

# ç›´æŽ¥è½‰æˆ numpy
all_price_diffs_array = filtered_df[columns_to_save].to_numpy(dtype=float)

# å„²å­˜
save_path = f"../data/ml/dataset/coin_price/{COIN_SHORT_NAME}_price_diff_past{SHIFT}days.npy"
np.save(save_path, all_price_diffs_array)

print(all_price_diffs_array[:10])  # é è¦½å‰ 20 ç­†
print(f"\nâœ… å·²å„²å­˜ {COIN_SHORT_NAME}_price_diff_past{SHIFT}days.npyï¼Œå½¢ç‹€: {all_price_diffs_array.shape}")



# # ---------------- æª¢æŸ¥ NaN ----------------
# for shift in day_shifts:
#     col_name = f"price_diff_{shift}d"
#     nan_rows = df_output[df_output[col_name].isna()]
#     if not nan_rows.empty:
#         print(f"\nä»¥ä¸‹æ—¥æœŸ {col_name} ç„¡æ³•è¨ˆç®—ï¼ˆå¯èƒ½ç¼ºå°‘ç•¶å¤©æˆ–æœªä¾† {shift} å¤©åƒ¹æ ¼ï¼‰:")
#         print(nan_rows[['date', 'price', 'tweet_count', 'has_tweet']])

# # ---------------- å„²å­˜å¤šçµ„ price_diff.npy ----------------
# all_price_diffs = []  # å»ºç«‹ price_diff çŸ©é™£ï¼ˆæ¯å€‹ row éƒ½æ˜¯ä¸åŒå¤©æ•¸çš„åƒ¹å·®ï¼‰

# for shift in day_shifts:
#     col_name = f"price_diff_{shift}d"

#     # éŽæ¿¾å‡ºæœ‰æŽ¨æ–‡ä¸”åƒ¹å·®ä¸æ˜¯ NaN
#     filtered_df = df_output[(df_output['has_tweet'] == True) & (df_output[col_name].notna())]

#     # ä¾ tweet_count é‡è¤‡åƒ¹å·®
#     expanded_price_diffs = []
#     for _, row in filtered_df.iterrows():
#         expanded_price_diffs.extend([row[col_name]] * row['tweet_count'])

#     all_price_diffs.append(expanded_price_diffs)
    
#     print(f"\nâœ… å·²åŠ å…¥ {COIN_SHORT_NAME}_price_diff_{shift}dayï¼ˆå…± {len(expanded_price_diffs)} ç­†ï¼‰")
#     print(expanded_price_diffs[:20])  # é è¦½å‰ 20 ç­†


# # è½‰æˆ numpy é™£åˆ—ä¸¦å„²å­˜
# all_price_diffs = np.array(all_price_diffs, dtype=float)
# all_price_diffs_T = all_price_diffs.T  # æˆ–è€… np.transpose(all_price_diffs)
# # save_path = f"../data/ml/dataset/coin_price/{COIN_SHORT_NAME}_price_diff_{SHIFT}.npy"
# save_path = f"../data/ml/dataset/coin_price/{COIN_SHORT_NAME}_price_diff.npy"
# np.save(save_path, all_price_diffs_T)

# print(f"\nâœ… å·²å„²å­˜çŸ©é™£ {all_price_diffs_T}ï¼Œå½¢ç‹€: {all_price_diffs_T.shape}")