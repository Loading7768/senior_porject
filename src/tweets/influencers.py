import json
import os
from glob import glob
from tqdm import tqdm
from collections import defaultdict
import re
from datetime import datetime
from pathlib import Path


# åŒ¯å…¥ config
import sys
parent_dir = Path(__file__).resolve().parent.parent
sys.path.append(str(parent_dir))
from config import COIN_SHORT_NAME, JSON_DICT_NAME

# æ‰€æœ‰æ¨æ–‡ JSON æª”æ¡ˆ
json_files = glob(f'../data/tweets/{COIN_SHORT_NAME}/*/*/*.json')

# è®€å–å½±éŸ¿è€…æ¸…å–®
influencers_path = "../data/tweets/influencers.json"
with open(influencers_path, 'r', encoding="utf-8-sig") as file:
    influencers_list = json.load(file)

# å»ºç«‹ï¼šuser_account å°æ‡‰æˆçµ±ä¸€ keyï¼ˆä½œç‚ºè¼¸å‡ºæª”åï¼‰
account_to_keyname = {}
user_accounts_set = set()
for inf in influencers_list:
    standard_name = inf["user_account"]  # æ±ºå®šè¼¸å‡ºæª”å
    username = inf["username"].lower()
    user_account = inf["user_account"].lower()
    
    account_to_keyname[username] = standard_name
    account_to_keyname[user_account] = standard_name
    user_accounts_set.add(user_account)

# æ‰€æœ‰ç¬¦åˆçš„æ¨æ–‡ï¼Œä¾å¸³è™Ÿåˆ†é–‹
grouped_tweets = defaultdict(list)           # æ‰€æœ‰ç›¸é—œæ¨æ–‡ï¼ˆåŒ…å«è¢«æåŠï¼‰
author_tweets = defaultdict(list)            # åƒ…ä½œè€…æœ¬äººæ¨æ–‡

for json_file in tqdm(json_files, desc="æŠ“å–ç‰¹å®šå¸³è™Ÿçš„æ¨æ–‡"):
    with open(json_file, 'r', encoding="utf-8-sig") as file:
        data = json.load(file)

    tweets = data.get(JSON_DICT_NAME, [])

    for tweet in tweets:
        username = tweet.get("username", "").lower()
        user_account = tweet.get("user_account", "").lower()
        text = tweet.get("text", "").lower()

        matched_key = None
        match_type = None

        # å„ªå…ˆæ¯”å°ä½œè€…èº«ä»½ï¼š(1) user_account  (2) username  (3) text
        if user_account != "" and (user_account in account_to_keyname):
            matched_key = account_to_keyname[user_account]
            match_type = "user_account"
            grouped_tweets[matched_key].append(tweet)
            author_tweets[matched_key].append(tweet)

        elif username in account_to_keyname:
            matched_key = account_to_keyname[username]
            match_type = "username"
            grouped_tweets[matched_key].append(tweet)
            author_tweets[matched_key].append(tweet)

        else:
            # åªé‡å° user_account æª¢æŸ¥ @æåŠ
            for ua in user_accounts_set:
                if re.search(rf'@{re.escape(ua)}\b', text):
                    matched_key = account_to_keyname[ua]
                    match_type = "text"
                    grouped_tweets[matched_key].append(tweet)
                    break

        if matched_key:
            tweet["match_type"] = match_type  # æ¨™è¨˜åŒ¹é…ä¾†æº
            # grouped_tweets[matched_key].append(tweet)

# è¼¸å‡ºæ¯å€‹å¸³è™Ÿä¸€å€‹ json æª”æ¡ˆ
output_dir = "../data/tweets/matched_influencer_tweets"
os.makedirs(output_dir, exist_ok=True)

match_priority = {"user_account": 0, "username": 1, "text": 2}

for account_name, tweets in grouped_tweets.items():
    output_path = os.path.join(output_dir, f"{account_name}.json")

    # ä¾ç…§ match_type æ’åº
    tweets.sort(key=lambda tweet: match_priority.get(tweet.get("match_type", "text")))

    # å¾ 1 é–‹å§‹æ¨™è¨˜ tweet_count
    for i, tweet in enumerate(tweets, start=1):
        tweet["tweet_count"] = i


    # === Spammer åˆ¤æ–·ï¼ˆæ»‘å‹•è¦–çª—3600ç§’ï¼‰ ===

    # åªæ‹¿ä½œè€…æœ¬äººæ¨æ–‡ä¾†åš spammer åˆ¤æ–·
    author_list = author_tweets.get(account_name, [])

    # æŠŠä½œè€…æœ¬äººæ¨æ–‡ä¾æ™‚é–“æ’åºï¼ˆä½ å¯èƒ½ä¹Ÿæƒ³åš tweet_count é€™æ­¥é©Ÿï¼‰
    author_list.sort(key=lambda tweet: tweet.get("created_at"))

    is_spammer = False
    times = []

    # å…ˆæŠŠæ‰€æœ‰æ¨æ–‡æ™‚é–“è½‰æˆ timestampï¼ˆç§’ï¼‰
    for tweet in author_list:
        created_time = tweet.get("created_at")
        if created_time:
            # ä¾å¯¦éš›æ ¼å¼èª¿æ•´è§£æ
            dt = datetime.strptime(created_time, "%a %b %d %H:%M:%S %z %Y")
            times.append(dt.timestamp())

    times.sort()

    start = 0  # è¦–çª—å·¦é‚Šç•Œ
    for end in range(len(times)):  # end: è¦–çª—å³é‚Šç•Œ
        # ä¿æŒ times[end] - times[start] <= 3600
        while times[end] - times[start] > 3600:
            start += 1
        if (end - start + 1) >= 6:  # è‡³å°‘ 6 ç¯‡
            is_spammer = True
            break

    # === å¦‚æœæ˜¯ spammerï¼Œé¡å¤–å­˜æª” ===
    output_spammer_path = os.path.join(output_dir, f"{account_name}_spammer.json")
    if is_spammer and author_list:
        for i, tweet in enumerate(author_list, start=1):
            tweet["tweet_count"] = i

        with open(output_spammer_path, "w", encoding="utf-8-sig") as f:
            json.dump(author_list, f, ensure_ascii=False, indent=4)

        print(f"ğŸ’¾ å·²å„²å­˜ spammer ä½œè€…æ¨æ–‡: {output_spammer_path}")


    # å„²å­˜ spammer æ¨™è¨˜
    output_data = {
        "account_name": account_name,
        "is_spammer": is_spammer,
        "tweets": tweets
    }

    # è¼¸å‡ºæ¯å€‹å¸³è™Ÿæ‰€æœ‰çš„æ¨æ–‡
    with open(output_path, "w", encoding="utf-8-sig") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=4)

    print(f"{account_name}.json: å…± {len(tweets)} ç­† | spammer: {is_spammer}")

print(f"âœ… å®Œæˆï¼šå…±è¼¸å‡º {len(grouped_tweets)} å€‹å½±éŸ¿è€…çš„æ¨æ–‡")
